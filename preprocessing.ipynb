{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0e07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import Normalizer, WordTokenizer, Stemmer, Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c071f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from hazm import Normalizer\n",
    "import re\n",
    "from hazm import Normalizer, word_tokenize, Stemmer, Lemmatizer\n",
    "\n",
    "# Hazm tools\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def clean_persian_text(text, do_stem=False, do_lemma=False):\n",
    "    # 1. Normalize (hazm): punctuation, tatweel, Arabic-to-Persian variants\n",
    "    text = normalizer.normalize(text)\n",
    "\n",
    "    # 2. Remove non-Persian characters (emojis, Latin, digits, etc.)\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
    "\n",
    "    # 3. Tokenize\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # 5. Optional: Lemmatize or Stem\n",
    "    if do_lemma:\n",
    "        words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    elif do_stem:\n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "\n",
    "    # 6. Join cleaned tokens back into string\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d008ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fa306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\ASUS\\Desktop\\github\\fine_tunning\\1\\cleaned_snappfood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585b35e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>comment_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>قرار بود  ساعته برسه ولی نیم ساعت زودتر از موق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب، ...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label  comment_length  \\\n",
       "0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح      0              47   \n",
       "1  قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...      1             132   \n",
       "2  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...      0              89   \n",
       "3  عالی بود همه چه درست و به اندازه و کیفیت خوب، ...      1              99   \n",
       "4                      شیرینی وانیلی فقط یک مدل بود.      1              29   \n",
       "\n",
       "                                     comment_cleaned  \n",
       "0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح  \n",
       "1  قرار بود  ساعته برسه ولی نیم ساعت زودتر از موق...  \n",
       "2  قیمت این مدل اصلا با کیفیتش سازگاری نداره فقط ...  \n",
       "3  عالی بود همه چه درست و به اندازه و کیفیت خوب ا...  \n",
       "4                       شیرینی وانیلی فقط یک مدل بود  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1195bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ae85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"comment_cleaned\"] = data[\"comment_cleaned\"].apply(clean_persian_text, do_lemma=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbca6f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    33675\n",
      "0    32298\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = data['label'].value_counts()\n",
    "\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493e5ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"comment_cleaned\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b4647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# label_mapping = {\"Sad\": 0, \"Happy\": 1, \"Intense Emotions\": 2, \"Neutral\": 3, \"Angry\": 4}\n",
    "# data[\"Label\"] = data[\"Label\"].map(lambda x: label_mapping[x])\n",
    "\n",
    "# # Verify the mapping\n",
    "# print(data[\"Label\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd58cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_comment.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
